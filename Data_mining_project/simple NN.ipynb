{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-251d241b2a97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangeDateFormat(date):\n",
    "    month = date // 100\n",
    "    day = date % 100\n",
    "    date = '2020-' + str(month) + '-' + str(day)\n",
    "    return pd.Timestamp(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for importing the original data.\n",
    "#info = pd.read_csv('/work/ma384/Share/Team_Repeat_Buyer/user_info_format1.csv')\n",
    "#log = pd.read_csv('/work/ma384/Share/Team_Repeat_Buyer/user_log_format1.csv')\n",
    "#df_train = pd.read_csv('/work/ma384/Share/Team_Repeat_Buyer/train_format1.csv')\n",
    "\n",
    "\n",
    "info = pd.read_csv('data_format1/user_info_format1.csv')\n",
    "log = pd.read_csv('data_format1/user_log_format1.csv')\n",
    "df_train = pd.read_csv('data_format1/train_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['age_range'] = info['age_range'].fillna(0)\n",
    "info['gender'] = info['gender'].fillna(2)\n",
    "info['age_range'] = info['age_range'].astype('category')\n",
    "info['gender'] = info['gender'].astype('category')\n",
    "info['age_range'] = info['age_range'].replace(8, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['time_stamp'] = log['time_stamp'].apply(lambda x: ChangeDateFormat(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_item_count = log[['seller_id','item_id']]\n",
    "seller_item_count = seller_item_count.drop_duplicates()\n",
    "seller_item_count['seller_item_count'] = 1\n",
    "seller_item_count = seller_item_count.groupby(['seller_id']).agg('sum')\n",
    "seller_item_count = seller_item_count.drop(columns=['item_id'])\n",
    "seller_item_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-79fe8c0dede0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseller_brand_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seller_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'brand_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mseller_brand_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseller_brand_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseller_brand_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseller_brand_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seller_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseller_brand_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"brand_id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"brand_count\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mseller_brand_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "seller_brand_count = log[['seller_id','brand_id']]\n",
    "seller_brand_count = seller_brand_count.drop_duplicates()\n",
    "seller_brand_count = seller_brand_count.groupby(['seller_id']).agg(len)\n",
    "seller_brand_count.rename(columns = {\"brand_id\": \"brand_count\"},inplace=True) \n",
    "seller_brand_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-81099577dca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitem_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcat_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cat_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbrand_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'brand_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseller_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seller_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "item_info = log['item_id'].value_counts()\n",
    "cat_info = log['cat_id'].value_counts()\n",
    "brand_info = log['brand_id'].value_counts()\n",
    "seller_info = log['seller_id'].value_counts()\n",
    "print(item_info.head(), item_info.size)\n",
    "print(cat_info.head(),cat_info.size)\n",
    "print(brand_info.head(),brand_info.size)\n",
    "print(seller_info.head(),seller_info.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = log.action_type\n",
    "actions = pd.get_dummies(actions,prefix='action_count')\n",
    "user_action = pd.concat([log.user_id,actions],axis=1)\n",
    "user_action = user_action.groupby('user_id').agg('sum')\n",
    "user_action.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train = pd.read_csv('/work/ma384/Share/Team_Repeat_Buyer/train_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seller = seller_item_count.merge(seller_brand_count,on='seller_id')\n",
    "df_train = df_Train.merge(seller,left_on='merchant_id',right_on='seller_id')\n",
    "df_train = df_train.merge(user_action,on='user_id')\n",
    "log_dummy = pd.get_dummies(log['action_type'],prefix='action')\n",
    "log_dummy = pd.concat([log.user_id,log.seller_id,actions],axis=1)\n",
    "log_dummy.columns = ['user_id', 'merchant_id', 'action_0', 'action_1',\n",
    "       'action_2', 'action_3']\n",
    "log_dummy = log_dummy.groupby(['user_id','merchant_id']).agg('sum')\n",
    "df_train = df_train.merge(log_dummy,on=['merchant_id','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train,test_size=0.2,random_state=0,shuffle=True,stratify=df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = train.label.values\n",
    "targets_test = test.label.values\n",
    "attributes_train = train.drop(['merchant_id','user_id','label'],axis=1).values\n",
    "attributes_test = test.drop(['merchant_id','user_id','label'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_train = (attributes_train - attributes_train.mean(axis=0))/attributes_train.std(axis=0)\n",
    "attributes_test = (attributes_test - attributes_test.mean(axis=0))/attributes_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN (Stacked LR with ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lr_with_relu = Sequential()\n",
    "stacked_lr_with_relu.add(Dense(10, input_shape=(10,), activation='relu'))\n",
    "stacked_lr_with_relu.add(Dense(2, input_shape=(10,), activation=None))\n",
    "\n",
    "stacked_lr_with_relu.compile(loss='sparse_categorical_crossentropy',\n",
    "                            optimizer=Adam(learning_rate=1e-5),\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "stacked_lr_with_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best = ModelCheckpoint('nn1.h5', save_best_only=True, verbose=2)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time()\n",
    "hist = stacked_lr_with_relu.fit(attributes_train, targets_train, epochs=50, \n",
    "                                callbacks=[save_best, early_stopping], \n",
    "                                validation_split=0.2, verbose=1)\n",
    "time_stop = time()\n",
    "time_elapsed = time_stop - time_start\n",
    "print(time_elapsed / 60, '(min)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeth_train = np.argmax(stacked_lr_with_relu.predict(attributes_train), axis=1)\n",
    "targeth_test  = np.argmax(stacked_lr_with_relu.predict(attributes_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train accuracy\", round((targeth_train == targets_train).mean(), 3))\n",
    "print(\"test accuracy\", round((targeth_test == targets_test).mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
